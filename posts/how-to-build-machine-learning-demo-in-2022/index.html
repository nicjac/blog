<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>How to Build a Machine Learning Demo in 2022 | Reasonable AI</title>
<meta name=keywords content="Deep Learning,AI,Demos,Gradio,Streamlit,Hugging Face">
<meta name=description content="Learn why you should build demos for your Machine Learning models in 2022, and how to do it in a way that fits your needs, skills, and audience.">
<meta name=author content="Nicolas Jaccard">
<link rel=canonical href=https://nicjac.dev/posts/how-to-build-machine-learning-demo-in-2022/>
<link crossorigin=anonymous href=/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css integrity="sha256-yIlj/i15RiAA/Q+xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://nicjac.dev/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=https://nicjac.dev/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=https://nicjac.dev/favicon-32x32.png>
<link rel=apple-touch-icon href=https://nicjac.dev/apple-touch-icon.png>
<link rel=mask-icon href=https://nicjac.dev/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.92.0">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript><script defer data-domain=nicjac.dev src=https://plausible.io/js/plausible.js></script><meta property="og:title" content="How to Build a Machine Learning Demo in 2022">
<meta property="og:description" content="Learn why you should build demos for your Machine Learning models in 2022, and how to do it in a way that fits your needs, skills, and audience.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://nicjac.dev/posts/how-to-build-machine-learning-demo-in-2022/"><meta property="og:image" content="https://nicjac.dev/images/demos/demo-splash.png"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2022-01-14T10:00:08+00:00">
<meta property="article:modified_time" content="2022-01-14T10:00:08+00:00"><meta property="og:site_name" content="Reasonable AI">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://nicjac.dev/images/demos/demo-splash.png">
<meta name=twitter:title content="How to Build a Machine Learning Demo in 2022">
<meta name=twitter:description content="Learn why you should build demos for your Machine Learning models in 2022, and how to do it in a way that fits your needs, skills, and audience.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://nicjac.dev/posts/"},{"@type":"ListItem","position":2,"name":"How to Build a Machine Learning Demo in 2022","item":"https://nicjac.dev/posts/how-to-build-machine-learning-demo-in-2022/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"How to Build a Machine Learning Demo in 2022","name":"How to Build a Machine Learning Demo in 2022","description":"Learn why you should build demos for your Machine Learning models in 2022, and how to do it in a way that fits your needs, skills, and audience.\n","keywords":["Deep Learning","AI","Demos","Gradio","Streamlit","Hugging Face"],"articleBody":"Learn why you should build demos for your Machine Learning models in 2022, and how to do it in a way that fits your needs, skills, and audience.\n Why Demos Are Now Essential Interactive demos of machine learning models are getting increasingly popular. After all, just like a picture paints a thousand words, nothing beats letting others interact directly with your model to generate interest. If you are interested in keeping up with recent trends or are looking for inspiration for your own demos, I highly recommend following the @ak92501 twitter account.\nOne example among many is a demo for a model transforming a portrait photograph into an illustration in the style used by the Netflix show Arcane. The ease of use of the demo and ability to quickly test the model with different input photographs was part of the reason why this project became so popular so quickly.\n Interactive demo for ArcaneGAN (using Gradio). Screenshot by author, demo located at https://huggingface.co/spaces/akhaliq/ArcaneGAN\n  There are many reasons why you might want to build an interactive demo:\n Getting a model tested by colleagues during development Prototype to seek investment in a new idea Disseminate research, potentially as a companion to a research paper Build a portfolio of work  Whatever your reason is, this article will provide some pointers and recommendations to make the most of this opportunity.\nHow To Build An Interactive Demo in 2022 There are a variety of ways to build an interactive demo for your Machine Learning model in 2022. Which one you pick will depend on:\n Your target audience Your software engineering skills Your monetary budget Your time budget  This article will cover three types of approaches: public notebook sharing, full-stack, and app libraries.\nTLDR - Which Approach Should I Use? The rest of the article will cover in details what you need to know about these three approaches. If you want a quick answer, the following table should help!\n     Google Colab Full-Stack App Libraries      Flexibility Low High Moderate to High    Target Audience Technical Any Any    Interactivity Low by Default High High    Non-ML dev work required None Significant Minimal    Deployment / Sharing Easy Difficult Easy    Costs Free Low to High Free    Time commitment Small High Small to Moderate    Productization No Yes Case by Case     Rule of thumb:\n Sharing with a technical audience where code visibility is useful and interactivity not critical? Use Google Colab (or equivalent) High likelihood for the demo to become a fully fledged product? Going the Full-Stack approach might save you time in the long run If none of the above, go with App Libraries and Hugging Face Spaces hosting  Public Notebook Sharing (Google Colab) Jupyter notebooks (and iPython before it) played a big part in cementing Python as the leading programming language for machine learning. While not without their faults, by enabling interactive data exploration and iterative development, notebooks quickly became an essential tool for machine learning enthusiasts. However, setting up a Jupyter environment can be challenging and potentially costly if hosting is required for remote access.\nGoogle Colab was a significant disruptor in this area – it democratized machine learning by offering a fully managed notebook experience without any setup or maintenance required, and provided free access to otherwise costly compute resources.\nColab made it trivial to share a notebook and have others interact with it, even if it required GPU acceleration. For example, the fastai documentation or even the recent fastai book are made available as Colab notebooks, allowing one to run and modify code as they go through the material.\n Screenshot of the quick start notebook for fastai in Google Colab. Screenshot by author, notebook located at https://colab.research.google.com/github/fastai/fastai/blob/master/nbs/quick_start.ipynb\n  Most notebooks can be made to work on Colab without much work required, and some widgets can be used to let users input their own data. If the notebook is versioned on a public Github repo, all it takes to share it is share a link with the following format:\nhttps://colab.research.google.com/github/$ACCOUNT/$REPO/blob/$BRANCH/$PATH_TO_NOTEBOOK where $ACCOUNT is the Github account, $REPO the repository, $BRANCH the branch, and $PATH_TO_NOTEBOOK the full path the the ipynb file.\nColab notebooks are not the best option if you are interested in sharing your work with the general public. However, they are very powerful tools to easily convey ideas to technical peers. So much so that pretty much all new developments in machine learning tend to come with a companion Colab notebook as standard. As an example, I explored a brand new approach to patch-based self-supervision using the Colab provided with my own input data (in this case, photographs of my cat Jasmine). It allowed me to get a much better understanding of this new research, at no cost to me.\n Screenshot of a Google Colab for a new self-supervision method featuring my cat Jasmine, notebook located at https://colab.research.google.com/github/facebookresearch/mae/blob/main/demo/mae_visualize.ipynb\n  Overall, interactivity is pretty limited. A possible way around this is the use of a library such as Gradio, which allows the creation of basic user interfaces directly in a notebook. Gradio will be covered in detail in the app libraries section.\nFor completeness' sake, I should mention that Amazon Web Services announced SageMaker Studio Lab, which is similar to Google Colab with some advantages such as persistent storage. I haven’t had a chance to explore it yet, but it could in theory be used in a similar way to Google Colab.\nPros of Colab notebooks:\n Free access to GPU compute Tight integration with Git to facilitate sharing Fully managed, no setup or maintenance  Cons of Colab notebooks:\n Limited to technical audiences, no suitable for a lay audience Limited interactivity by default, can be improved with libraries such as Gradio GPU availability can be hit or miss Some external storage required (e.g. to store model artefacts)  Full-stack This approach to creating an interactive demo is the most demanding, but potentially one that will pay off in the long run. It is full-stack, because it involves two components:\n A back end responsible for loading and serving the model as a REST API A front end to provide UI elements to interact with the back-end  The obvious downside is that it requires to be comfortable working on both those components, or at least be willing to learn. However, this approach is the most flexible, and can be used as a stepping stone to deploy a fully fledged production environment without starting from scratch.\nBefore diving into the back and front end components below, let’s have a look at the pros and cons of the full-stack approach.\nPros of the full-stack approach:\n As flexible as needed Can include additional features such as authentication Can be used as a basis for production deployment without starting from scratch Can be optimized for performance  Cons of the full-stack approach:\n Knowledge in back and front end development required Time consuming development and deployment Requires infrastructure for deployment  Back End An exhaustive discussion of the different technology stacks for back end development is out of scope of this article. However, given that most machine learning engineers working on machine learning applications are at least familiar with Python, we will focus on Python-based back end solutions.\n Different tools for back end development: general-purpose web frameworks, serving libraries, and framework-specific serving libraries. Image by the author.\n  The goal of the back end is to act as a wrapper for a model so that it can be queried via HTTP requests from the front end, something referred to as model serving. In order to do so, one would typically use a web framework. For a long time, Flask was the standard for Python-based web frameworks, and is indeed still very popular. However, FastaAPI is quickly becoming the new favorite, thanks to impressive performance and native support for asynchronous operations. This article is a good starting point to understand how a simple model can be deployed using FastAPI, while this tutorial provides a complete overview of all the steps required to serve a PyTorch model with GPU support.\nUsing a general-purpose framework such as FastAPI involves writing a lot of boilerplate code just to get your API endpoint up and running. If deploying a model for a demo is the only thing you are interested in and you do not mind losing some flexibility, you might want to use a specialized serving framework instead. One example is BentoML, which will allow you to get an optimized serving endpoint for your model up and running much faster and with less overhead than a generic web framework. Framework-specific serving solutions such as Tensorflow Serving and TorchServe typically offer optimized performance but can only be used to serve models trained using Tensorflow or PyTorch, respectively.\nFront End The front end is responsible for providing a user interface to interact with the back end serving the model. In most cases, it will be a mean to input data (such as text for natural language processing, or images for computer vision) and to display model outputs. Having this user interface live in a web browser makes your demo accessible without additional dependencies.\nFront end development is where you will likely have to leave Python behind. While libraries such as Skulpt and Brython enable the use of Python in the browser, I highly recommend using Javascript as the very large community means that tutorials are numerous, and it will be much easier to seek help if needed. The two most popular libraries to build user interfaces in Javascript are React (tutorial for ML demo) and Vue.js (tutorial for ML demo). Using a general-purpose framework will give the flexibility needed to tailor the UI to your exact requirements.\nDeployment Once your back and front end components are ready, they must be deployed somewhere publicly accessible. Again, flexibility is the name of the game here. Services like Heroku offer a managed (and free, depending on usage) experience for deployment of applications. Public cloud providers such as Amazon Web Services, Azure, or Google Cloud could be an option and a small demo would likely fit nicely within their free tier offerings.\nWhatever path you decide to take, I recommend you consider containerization of your demo using Docker. This way, the same exact container image is used for local testing during development and for deployment on your hosting provider, helping avoid bad surprises due to changes in environment.\nApp Libraries So what if you want something almost as flexible as what is possible with the full-stack approach, but without the development requirements? Well, you are in luck because the past few years have seen the emergence of Python libraries that allow the creation of impressively interactive demos with only a few lines of code. In this article, we are going to focus on two of the most promising libraries: Gradio and Streamlit. There are notable differences between the two that will be explored below, but the high level idea is the same: eliminate most of the painful back and front end work outlined in the full-stack section, albeit at the cost of some flexibility.\nGradio Gradio was already mentioned in the Google Colab section as it can be used to add interactive elements to notebooks. As shown in the library’s getting started page, building an interface only takes a few lines of Python code.\nimport gradio as gr def greet(name): return \"Hello \" + name + \"!!\" iface = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\") iface.launch() If you are working in a notebook, the UI will show right there and then. If running from a script, a browser window will open and point to http://localhost:7860. The reason why this works is that Gradio essentially runs an API server in the background for you, thus taking care of much of the work discussed in the full-stack section. It used to leverage Flask to create the local API server, but it very recently switched to using FastAPI.\nIn the code snippet above, the greet function would be replaced with the inference code for your model. Note that both inputs and outputs are set to text, so the UI will automatically default to the widgets necessary to handle text-based tasks. Similar widgets exist for most common use-cases, including computer vision and audio processing. In addition, Gradio offers very handy features such as the ability to take a screenshot or for the user to flag if the output shown is unexpected (e.g. if processing failed).\nIf you want to share your user interface with the world, using the share=True argument in the launch method will provide you with a gradio.app URL that points to your demo. Note that this is only forwarding request to your machine, so it will only work as long as your script or notebook is running, and the link automatically expires after 72 hours. See the section about hosting below as a way around those limitations.\n Default Gradio UI for text inputs and outputs produced by a few lines of code. Screenshot by the author.\n  Gradio is laser-focused on building user interfaces for machine learning models, and this focus means that it will take care of almost everything for you and will work out of the box with very little configuration required.\nPros of Gradio:\n Quick and easy setup out of the box Runs directly in notebooks Absolutely no knowledge of web development required Apps are easily shared Good selection of built-in UI elements Features such as screenshots or output flagging are very handy for demos  Cons of Gradio:\n Limited control over the UI layout Not suitable for complex apps (e.g. state management, caching)  Streamlit Streamlit is a library to build and share data apps. Their curated gallery showcases examples of data visualization apps, dashboards, interactive tutorials, and, of course, machine learning demos.\nStreamlit can be used to build complex applications, which comes at the cost of a higher barrier of entry compared to Gradio. For example, it cannot be run directly in a notebook – a command line tool is used to start the application from a script. A live reload approach is adopted, whereby changes made to the code are automatically reflected in the application running in the browser, allowing for quick iterations.\nStreamlit comes with advanced features such as caching, which can help prevent long running tasks (for example downloading and preparing a model for inference) to not be ran multiple times unnecessarily and the ability to build stateful applications (where information is preserved for the duration of a user session). Those features enable use-cases beyond simple machine learning demos. On the UI side of things, the library has a large number of built-in widgets and can be further extended through the support of third-party components.\n A streamlit app converting portrait photographs to comic book characters. Screenshot by author, demo located at https://share.streamlit.io/nathannguyen-dev/comic_me_v1/main.py\n  Streamlit offers a managed service for app sharing called Streamlit Cloud. As of this writing, one private (requiring authentication) and unlimited public apps can be deployed using Streamlit Cloud with the free plan. Alternatively, Streamlit apps are easily containerized and deployed using Docker.\nIf you are interested in deploying both Gradio and Streamlit apps, Hugging Face Spaces might be the way to go.\nPros of Streamlit:\n Quick setup Advanced features such as caching and state management allow for complex apps to be built Large selection of built-in UI widgets Highly customizable UI layout Extensible through support for custom third-party components  Cons of Streamlit:\n Sharing applications is not as trivial as it is using Gradio Complex apps require some understanding of advanced web development concepts Not compatible with notebooks Lacking some basic built-in features for ML demos (e.g. flagging of unexpected inputs/outputs)  The Hugging Face Spaces Revolution Deploying apps developed using either Gradio or Streamlit got a whole lot easier when Hugging Face added Spaces to their ecosystem of ML products and tools. Spaces are similar to Github Pages – code is committed to a repository, and the app is automatically build and served. When creating a space, you pick between Streamlit, Gradio, and Static (which more or less replicates Github Pages' static website hosting capabilities). The Space is then automatically setup to accommodate your library of choice. Useful features such as versioning and the ability for users to like a space make it a great experience for the deployment of a public machine learning demo.\nSimilarly to how Google Colab democratized access to compute resources required for state-of-the-art machine learning models, Hugging Face Spaces allow anyone to host a demo for the world to check out. This means that the entire machine learning workflow, from model training to deployment of an interactive demo, can now be carried out for free and almost entirely in Python.\n","wordCount":"2764","inLanguage":"en","datePublished":"2022-01-14T10:00:08Z","dateModified":"2022-01-14T10:00:08Z","author":{"@type":"Person","name":"Nicolas Jaccard"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://nicjac.dev/posts/how-to-build-machine-learning-demo-in-2022/"},"publisher":{"@type":"Organization","name":"Reasonable AI","logo":{"@type":"ImageObject","url":"https://nicjac.dev/favicon.ico"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://nicjac.dev/ accesskey=h title="Reasonable AI (Alt + H)">Reasonable AI</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
<li>
<a href=https://nicjac.dev/about/ title="About Me">
<span>About Me</span>
</a>
</li>
<li>
<a href=https://nicjac.dev/posts/ title=Posts>
<span>Posts</span>
</a>
</li>
<li>
<a href=https://nicjac.dev/categories/ title=Categories>
<span>Categories</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<div class=breadcrumbs><a href=https://nicjac.dev/>Home</a>&nbsp;»&nbsp;<a href=https://nicjac.dev/posts/>Posts</a></div>
<h1 class=post-title>
How to Build a Machine Learning Demo in 2022
</h1>
<div class=post-meta><span title="2022-01-14 10:00:08 +0000 UTC">14 January, 2022</span>&nbsp;·&nbsp;13 min&nbsp;·&nbsp;Nicolas Jaccard
</div>
</header> <div class=toc>
<details>
<summary accesskey=c title="(Alt + C)">
<span class=details>Table of Contents</span>
</summary>
<div class=inner><ul>
<li>
<a href=#why-demos-are-now-essential aria-label="Why Demos Are Now Essential">Why Demos Are Now Essential</a></li>
<li>
<a href=#how-to-build-an-interactive-demo-in-2022 aria-label="How To Build An Interactive Demo in 2022">How To Build An Interactive Demo in 2022</a><ul>
<li>
<a href=#tldr---which-approach-should-i-use aria-label="TLDR - Which Approach Should I Use?">TLDR - Which Approach Should I Use?</a></li>
<li>
<a href=#public-notebook-sharing-google-colab aria-label="Public Notebook Sharing (Google Colab)">Public Notebook Sharing (Google Colab)</a></li>
<li>
<a href=#full-stack aria-label=Full-stack>Full-stack</a><ul>
<li>
<a href=#back-end aria-label="Back End">Back End</a></li>
<li>
<a href=#front-end aria-label="Front End">Front End</a></li>
<li>
<a href=#deployment aria-label=Deployment>Deployment</a></li></ul>
</li>
<li>
<a href=#app-libraries aria-label="App Libraries">App Libraries</a><ul>
<li>
<a href=#gradio aria-label=Gradio>Gradio</a></li>
<li>
<a href=#streamlit aria-label=Streamlit>Streamlit</a></li>
<li>
<a href=#the-hugging-face-spaces-revolution aria-label="The Hugging Face Spaces Revolution">The Hugging Face Spaces Revolution</a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</details>
</div>
<div class=post-content><p>Learn <strong>why</strong> you should build demos for your Machine Learning models in 2022, and <strong>how</strong> to do it in a way that fits your needs, skills, and audience.</p>
<figure class=align-center>
<img loading=lazy src=/images/demos/demo-splash.png#center>
</figure>
<h2 id=why-demos-are-now-essential>Why Demos Are Now Essential<a hidden class=anchor aria-hidden=true href=#why-demos-are-now-essential>#</a></h2>
<p>Interactive demos of machine learning models are getting increasingly popular. After all, just like a picture paints a thousand words, nothing beats letting others interact directly with your model to generate interest. If you are interested in keeping up with recent trends or are looking for inspiration for your own demos, I highly recommend following the <a href=https://twitter.com/ak92501>@ak92501 twitter account</a>.</p>
<p>One example among many is a demo for a model transforming a portrait photograph into an illustration in the style used by the Netflix show Arcane. The ease of use of the demo and ability to quickly test the model with different input photographs was part of the reason why this project became so popular so quickly.</p>
<figure class=align-center>
<img loading=lazy src=/images/demos/arcaneGAN.png#center alt="Interactive demo for ArcaneGAN (using Gradio). Screenshot by author, demo located at https://huggingface.co/spaces/akhaliq/ArcaneGAN"> <figcaption>
<p>Interactive demo for ArcaneGAN (using <a href=#gradio>Gradio</a>). Screenshot by author, demo located at <a href=https://huggingface.co/spaces/akhaliq/ArcaneGAN>https://huggingface.co/spaces/akhaliq/ArcaneGAN</a></p>
</figcaption>
</figure>
<p>There are many reasons why you might want to build an interactive demo:</p>
<ul>
<li>Getting a model tested by colleagues during development</li>
<li>Prototype to seek investment in a new idea</li>
<li>Disseminate research, potentially as a companion to a research paper</li>
<li>Build a portfolio of work</li>
</ul>
<p>Whatever your reason is, this article will provide some pointers and recommendations to make the most of this opportunity.</p>
<h2 id=how-to-build-an-interactive-demo-in-2022>How To Build An Interactive Demo in 2022<a hidden class=anchor aria-hidden=true href=#how-to-build-an-interactive-demo-in-2022>#</a></h2>
<p>There are a variety of ways to build an interactive demo for your Machine Learning model in 2022. Which one you pick will depend on:</p>
<ul>
<li>Your target audience</li>
<li>Your software engineering skills</li>
<li>Your monetary budget</li>
<li>Your time budget</li>
</ul>
<p>This article will cover three types of approaches: <a href=#public-notebook-sharing-google-colab>public notebook sharing</a>, <a href=#full-stack>full-stack</a>, and <a href=#app-libraries>app libraries</a>.</p>
<h3 id=tldr---which-approach-should-i-use>TLDR - Which Approach Should I Use?<a hidden class=anchor aria-hidden=true href=#tldr---which-approach-should-i-use>#</a></h3>
<p>The rest of the article will cover in details what you need to know about these three approaches. If you want a quick answer, the following table should help!</p>
<table>
<thead>
<tr>
<th> </th>
<th><a href=#public-notebook-sharing-google-colab>Google Colab</a></th>
<th><a href=#full-stack>Full-Stack</a></th>
<th><a href=#app-libraries>App Libraries</a></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Flexibility</strong></td>
<td>Low</td>
<td>High</td>
<td>Moderate to High</td>
<td></td>
</tr>
<tr>
<td><strong>Target Audience</strong></td>
<td>Technical</td>
<td>Any</td>
<td>Any</td>
<td></td>
</tr>
<tr>
<td><strong>Interactivity</strong></td>
<td>Low by Default</td>
<td>High</td>
<td>High</td>
<td></td>
</tr>
<tr>
<td><strong>Non-ML dev work required</strong></td>
<td>None</td>
<td>Significant</td>
<td>Minimal</td>
<td></td>
</tr>
<tr>
<td><strong>Deployment / Sharing</strong></td>
<td>Easy</td>
<td>Difficult</td>
<td>Easy</td>
<td></td>
</tr>
<tr>
<td><strong>Costs</strong></td>
<td>Free</td>
<td>Low to High</td>
<td>Free</td>
<td></td>
</tr>
<tr>
<td><strong>Time commitment</strong></td>
<td>Small</td>
<td>High</td>
<td>Small to Moderate</td>
<td></td>
</tr>
<tr>
<td><strong>Productization</strong></td>
<td>No</td>
<td>Yes</td>
<td>Case by Case</td>
<td></td>
</tr>
</tbody>
</table>
<p>Rule of thumb:</p>
<ul>
<li>Sharing with a technical audience where code visibility is useful and interactivity not critical? Use <a href=#public-notebook-sharing-google-colab>Google Colab</a> (or equivalent)</li>
<li>High likelihood for the demo to become a fully fledged product? Going the <a href=#full-stack>Full-Stack</a> approach might save you time in the long run</li>
<li>If none of the above, go with <a href=#app-libraries>App Libraries</a> and <a href=#the-hugging-face-spaces-revolution>Hugging Face Spaces hosting</a></li>
</ul>
<h3 id=public-notebook-sharing-google-colab>Public Notebook Sharing (Google Colab)<a hidden class=anchor aria-hidden=true href=#public-notebook-sharing-google-colab>#</a></h3>
<p>Jupyter notebooks (and iPython before it) played a big part in cementing Python as the leading programming language for machine learning. While not without their faults, by enabling interactive data exploration and iterative development, notebooks quickly became an essential tool for machine learning enthusiasts. However, setting up a Jupyter environment can be challenging and potentially costly if hosting is required for remote access.</p>
<p><a href=colab.research.google.com>Google Colab</a> was a significant disruptor in this area &ndash; it democratized machine learning by offering a fully managed notebook experience without any setup or maintenance required, and provided free access to otherwise costly compute resources.</p>
<p>Colab made it trivial to share a notebook and have others interact with it, even if it required GPU acceleration. For example, the <a href=https://colab.research.google.com/github/fastai/fastai/blob/master/nbs/quick_start.ipynb>fastai documentation</a> or even the recent <a href=https://colab.research.google.com/github/fastai/fastbook/blob/master/01_intro.ipynb>fastai book</a> are made available as Colab notebooks, allowing one to run and modify code as they go through the material.</p>
<figure class=align-center>
<img loading=lazy src=/images/demos/colab-fastai.png#center alt="Screenshot of the quick start notebook for fastai in Google Colab. Screenshot by author, notebook located at https://colab.research.google.com/github/fastai/fastai/blob/master/nbs/quick_start.ipynb"> <figcaption>
<p>Screenshot of the quick start notebook for fastai in Google Colab. Screenshot by author, notebook located at <a href=https://colab.research.google.com/github/fastai/fastai/blob/master/nbs/quick_start.ipynb>https://colab.research.google.com/github/fastai/fastai/blob/master/nbs/quick_start.ipynb</a></p>
</figcaption>
</figure>
<p>Most notebooks can be made to work on Colab without much work required, and some widgets can be used to let users input their own data. If the notebook is versioned on a public Github repo, all it takes to share it is share a link with the following format:</p>
<pre tabindex=0><code>https://colab.research.google.com/github/$ACCOUNT/$REPO/blob/$BRANCH/$PATH_TO_NOTEBOOK
</code></pre><p>where <code>$ACCOUNT</code> is the Github account, <code>$REPO</code> the repository, <code>$BRANCH</code> the branch, and <code>$PATH_TO_NOTEBOOK</code> the full path the the <code>ipynb</code> file.</p>
<p>Colab notebooks are not the best option if you are interested in sharing your work with the general public. However, they are very powerful tools to easily convey ideas to technical peers. So much so that pretty much all new developments in machine learning tend to come with a companion Colab notebook as standard. As an example, I explored a brand new approach to <a href=https://arxiv.org/abs/2111.06377>patch-based self-supervision</a> using the <a href=https://colab.research.google.com/github/facebookresearch/mae/blob/main/demo/mae_visualize.ipynb>Colab provided</a> with my own input data (in this case, photographs of my cat Jasmine). It allowed me to get a much better understanding of this new research, at no cost to me.</p>
<figure class=align-center>
<img loading=lazy src=/images/demos/demo-colab-mae.png#center alt="Screenshot of a Google Colab for a new self-supervision method featuring my cat Jasmine, notebook located at https://colab.research.google.com/github/facebookresearch/mae/blob/main/demo/mae_visualize.ipynb"> <figcaption>
<p>Screenshot of a Google Colab for a new self-supervision method featuring my cat Jasmine, notebook located at <a href=https://colab.research.google.com/github/facebookresearch/mae/blob/main/demo/mae_visualize.ipynb>https://colab.research.google.com/github/facebookresearch/mae/blob/main/demo/mae_visualize.ipynb</a></p>
</figcaption>
</figure>
<p>Overall, interactivity is pretty limited. A possible way around this is the use of a library such as <a href=https://gradio.app/>Gradio</a>, which allows the creation of basic user interfaces directly in a notebook. Gradio will be covered in detail in the <a href=#app-libraries>app libraries</a> section.</p>
<p>For completeness' sake, I should mention that Amazon Web Services announced <a href=https://aws.amazon.com/sagemaker/studio-lab/>SageMaker Studio Lab</a>, which is similar to Google Colab with some advantages such as persistent storage. I haven&rsquo;t had a chance to explore it yet, but it could in theory be used in a similar way to Google Colab.</p>
<p><em>Pros of Colab notebooks</em>:</p>
<ul>
<li>Free access to GPU compute</li>
<li>Tight integration with Git to facilitate sharing</li>
<li>Fully managed, no setup or maintenance</li>
</ul>
<p><em>Cons of Colab notebooks</em>:</p>
<ul>
<li>Limited to technical audiences, no suitable for a lay audience</li>
<li>Limited interactivity by default, can be improved with libraries such as Gradio</li>
<li>GPU availability can be hit or miss</li>
<li>Some external storage required (e.g. to store model artefacts)</li>
</ul>
<h3 id=full-stack>Full-stack<a hidden class=anchor aria-hidden=true href=#full-stack>#</a></h3>
<p>This approach to creating an interactive demo is the most demanding, but potentially one that will pay off in the long run. It is full-stack, because it involves two components:</p>
<ul>
<li>A <strong>back end</strong> responsible for loading and serving the model as a REST API</li>
<li>A <strong>front end</strong> to provide UI elements to interact with the back-end</li>
</ul>
<p>The obvious downside is that it requires to be comfortable working on both those components, or at least be willing to learn. <strong>However, this approach is the most flexible, and can be used as a stepping stone to deploy a fully fledged production environment without starting from scratch</strong>.</p>
<p>Before diving into the back and front end components below, let&rsquo;s have a look at the pros and cons of the full-stack approach.</p>
<p><em>Pros of the full-stack approach</em>:</p>
<ul>
<li>As flexible as needed</li>
<li>Can include additional features such as authentication</li>
<li>Can be used as a basis for production deployment without starting from scratch</li>
<li>Can be optimized for performance</li>
</ul>
<p><em>Cons of the full-stack approach</em>:</p>
<ul>
<li>Knowledge in back and front end development required</li>
<li>Time consuming development and deployment</li>
<li>Requires infrastructure for deployment</li>
</ul>
<h4 id=back-end>Back End<a hidden class=anchor aria-hidden=true href=#back-end>#</a></h4>
<p>An exhaustive discussion of the different technology stacks for back end development is out of scope of this article. However, given that most machine learning engineers working on machine learning applications are at least familiar with Python, we will focus on Python-based back end solutions.</p>
<figure class=align-center>
<img loading=lazy src=/images/demos/demo-back-end-examples.png#center alt="Different tools for back end development: general-purpose web frameworks, serving libraries, and framework-specific serving libraries. Image by the author."> <figcaption>
<p>Different tools for back end development: general-purpose web frameworks, serving libraries, and framework-specific serving libraries. Image by the author.</p>
</figcaption>
</figure>
<p>The goal of the back end is to act as a wrapper for a model so that it can be queried via <code>HTTP</code> requests from the front end, something referred to as <em>model serving</em>. In order to do so, one would typically use a web framework. For a long time, <a href=https://flask.palletsprojects.com/>Flask</a> was the standard for Python-based web frameworks, and is indeed still very popular. However, <a href=https://fastapi.tiangolo.com/>FastaAPI</a> is quickly becoming the new favorite, thanks to impressive performance and native support for asynchronous operations. <a href=https://towardsdatascience.com/how-you-can-quickly-deploy-your-ml-models-with-fastapi-9428085a87bf>This article</a> is a good starting point to understand how a simple model can be deployed using FastAPI, while this <a href=https://medium.com/@mingc.me/deploying-pytorch-model-to-production-with-fastapi-in-cuda-supported-docker-c161cca68bb8>tutorial</a> provides a complete overview of all the steps required to serve a PyTorch model with GPU support.</p>
<p>Using a general-purpose framework such as FastAPI involves writing a lot of boilerplate code just to get your API endpoint up and running. If deploying a model for a demo is the only thing you are interested in and you do not mind losing some flexibility, you might want to use a specialized serving framework instead. One example is <a href=https://github.com/bentoml/BentoML>BentoML</a>, which will allow you to get an optimized serving endpoint for your model up and running much faster and with less overhead than a generic web framework. Framework-specific serving solutions such as <a href=https://www.tensorflow.org/tfx/guide/serving>Tensorflow Serving</a> and <a href=https://pytorch.org/serve/>TorchServe</a> typically offer optimized performance but can only be used to serve models trained using Tensorflow or PyTorch, respectively.</p>
<h4 id=front-end>Front End<a hidden class=anchor aria-hidden=true href=#front-end>#</a></h4>
<p>The front end is responsible for providing a user interface to interact with the back end serving the model. In most cases, it will be a mean to input data (such as text for natural language processing, or images for computer vision) and to display model outputs. Having this user interface live in a web browser makes your demo accessible without additional dependencies.</p>
<p>Front end development is where you will likely have to leave Python behind. While libraries such as <a href=https://skulpt.org/>Skulpt</a> and <a href=https://brython.info/>Brython</a> enable the use of Python in the browser, I highly recommend using Javascript as the very large community means that tutorials are numerous, and it will be much easier to seek help if needed. The two most popular libraries to build user interfaces in Javascript are <a href=https://reactjs.org/>React</a> (<a href=https://hackernoon.com/frontend-dev-how-to-build-a-predictive-machine-learning-site-with-react-and-python-part-3>tutorial for ML demo</a>) and <a href=https://vuejs.org/>Vue.js</a> (<a href=https://royleekiat.com/2020/11/05/how-to-build-a-vuejs-frontend-for-your-machine-learning-prediction-input-and-output/>tutorial for ML demo</a>). Using a general-purpose framework will give the flexibility needed to tailor the UI to your exact requirements.</p>
<h4 id=deployment>Deployment<a hidden class=anchor aria-hidden=true href=#deployment>#</a></h4>
<p>Once your back and front end components are ready, they must be deployed somewhere publicly accessible. Again, flexibility is the name of the game here. Services like <a href=https://www.heroku.com/>Heroku</a> offer a managed (and free, depending on usage) experience for deployment of applications. Public cloud providers such as Amazon Web Services, Azure, or Google Cloud could be an option and a small demo would likely fit nicely within their free tier offerings.</p>
<p>Whatever path you decide to take, I recommend you consider containerization of your demo using Docker. This way, the same exact container image is used for local testing during development and for deployment on your hosting provider, helping avoid bad surprises due to changes in environment.</p>
<h3 id=app-libraries>App Libraries<a hidden class=anchor aria-hidden=true href=#app-libraries>#</a></h3>
<p>So what if you want something <em>almost</em> as flexible as what is possible with the full-stack approach, but without the development requirements? Well, you are in luck because the past few years have seen the emergence of Python libraries that allow the creation of impressively interactive demos with only a few lines of code. In this article, we are going to focus on two of the most promising libraries: <a href=https://gradio.app/>Gradio</a> and <a href=https://streamlit.io/>Streamlit</a>. There are notable differences between the two that will be explored below, but the high level idea is the same: eliminate most of the painful back and front end work outlined in the <a href=#full-stack>full-stack</a> section, albeit at the cost of some flexibility.</p>
<h4 id=gradio>Gradio<a hidden class=anchor aria-hidden=true href=#gradio>#</a></h4>
<p><a href=https://gradio.app/>Gradio</a> was already mentioned in the <a href=#public-notebook-sharing-google-colab>Google Colab</a> section as it can be used to add interactive elements to notebooks. As shown in the <a href=https://gradio.app/getting_started/>library&rsquo;s getting started page</a>, building an interface only takes a few lines of Python code.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> gradio <span style=color:#66d9ef>as</span> gr

<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>greet</span>(name):
  <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#34;Hello &#34;</span> <span style=color:#f92672>+</span> name <span style=color:#f92672>+</span> <span style=color:#e6db74>&#34;!!&#34;</span>

iface <span style=color:#f92672>=</span> gr<span style=color:#f92672>.</span>Interface(fn<span style=color:#f92672>=</span>greet, inputs<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;text&#34;</span>, outputs<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;text&#34;</span>)
iface<span style=color:#f92672>.</span>launch()
</code></pre></div><p>If you are working in a notebook, the UI will show right there and then. If running from a script, a browser window will open and point to <code>http://localhost:7860</code>. The reason why this works is that Gradio essentially runs an API server in the background for you, thus taking care of much of the work discussed in the <a href=#full-stack>full-stack</a> section. It used to leverage Flask to create the local API server, but it very recently <a href=https://twitter.com/abidlabs/status/1479895680219029516>switched to using FastAPI</a>.</p>
<p>In the code snippet above, the <code>greet</code> function would be replaced with the inference code for your model. Note that both <code>inputs</code> and <code>outputs</code> are set to text, so the UI will automatically default to the widgets necessary to handle text-based tasks. Similar widgets exist for most common use-cases, including computer vision and audio processing. In addition, Gradio offers very handy features such as the ability to take a screenshot or for the user to flag if the output shown is unexpected (e.g. if processing failed).</p>
<p>If you want to share your user interface with the world, using the <code>share=True</code> argument in the <code>launch</code> method will provide you with a <code>gradio.app</code> URL that points to your demo. Note that this is only forwarding request to your machine, so it will only work as long as your script or notebook is running, and the link automatically expires after 72 hours. See the <a href=#the-hugging-face-spaces-revolution>section about hosting</a> below as a way around those limitations.</p>
<figure class=align-center>
<img loading=lazy src=/images/demos/demo-gradio.png#center alt="Default Gradio UI for text inputs and outputs produced by a few lines of code. Screenshot by the author."> <figcaption>
<p>Default Gradio UI for text inputs and outputs produced by a few lines of code. Screenshot by the author.</p>
</figcaption>
</figure>
<p>Gradio is laser-focused on building user interfaces for machine learning models, and this focus means that it will take care of almost everything for you and will work out of the box with very little configuration required.</p>
<p><em>Pros of Gradio</em>:</p>
<ul>
<li>Quick and easy setup out of the box</li>
<li>Runs directly in notebooks</li>
<li>Absolutely no knowledge of web development required</li>
<li>Apps are easily shared</li>
<li>Good selection of built-in UI elements</li>
<li>Features such as screenshots or output flagging are very handy for demos</li>
</ul>
<p><em>Cons of Gradio</em>:</p>
<ul>
<li>Limited control over the UI layout</li>
<li>Not suitable for complex apps (e.g. state management, caching)</li>
</ul>
<h4 id=streamlit>Streamlit<a hidden class=anchor aria-hidden=true href=#streamlit>#</a></h4>
<p><a href=https://streamlit.io/>Streamlit</a> is a library to build and share data apps. Their <a href=https://streamlit.io/gallery>curated gallery</a> showcases examples of data visualization apps, dashboards, interactive tutorials, and, of course, machine learning demos.</p>
<p>Streamlit can be used to build complex applications, which comes at the cost of a higher barrier of entry compared to Gradio. For example, it cannot be run directly in a notebook &ndash; a command line tool is used to start the application from a script. A live reload approach is adopted, whereby changes made to the code are automatically reflected in the application running in the browser, allowing for quick iterations.</p>
<p>Streamlit comes with advanced features such as caching, which can help prevent long running tasks (for example downloading and preparing a model for inference) to not be ran multiple times unnecessarily and the ability to build stateful applications (where information is preserved for the duration of a user session). Those features enable use-cases beyond simple machine learning demos. On the UI side of things, the library has a large number of built-in widgets and can be further extended through the support of <a href=https://streamlit.io/components>third-party components</a>.</p>
<figure class=align-center>
<img loading=lazy src=/images/demos/demo-streamlit.png#center alt="A streamlit app converting portrait photographs to comic book characters. Screenshot by author, demo located at https://share.streamlit.io/nathannguyen-dev/comic_me_v1/main.py"> <figcaption>
<p>A streamlit app converting portrait photographs to comic book characters. Screenshot by author, demo located at <a href=https://share.streamlit.io/nathannguyen-dev/comic_me_v1/main.py>https://share.streamlit.io/nathannguyen-dev/comic_me_v1/main.py</a></p>
</figcaption>
</figure>
<p>Streamlit offers a managed service for app sharing called <a href=https://docs.streamlit.io/streamlit-cloud/get-started/deploy-an-app>Streamlit Cloud</a>. <a href=https://blog.streamlit.io/deploy-a-private-app-for-free/>As of this writing</a>, one private (requiring authentication) and unlimited public apps can be deployed using Streamlit Cloud with the free plan. Alternatively, Streamlit apps are easily containerized and <a href=https://towardsdatascience.com/create-an-awesome-streamlit-app-deploy-it-with-docker-a3d202a636e8>deployed using Docker</a>.</p>
<p>If you are interested in deploying both Gradio and Streamlit apps, <a href=#the-hugging-face-spaces-revolution>Hugging Face Spaces</a> might be the way to go.</p>
<p><em>Pros of Streamlit</em>:</p>
<ul>
<li>Quick setup</li>
<li>Advanced features such as caching and state management allow for complex apps to be built</li>
<li>Large selection of built-in UI widgets</li>
<li>Highly customizable UI layout</li>
<li>Extensible through support for custom third-party components</li>
</ul>
<p><em>Cons of Streamlit</em>:</p>
<ul>
<li>Sharing applications is not as trivial as it is using Gradio</li>
<li>Complex apps require <em>some</em> understanding of advanced web development concepts</li>
<li>Not compatible with notebooks</li>
<li>Lacking some basic built-in features for ML demos (e.g. flagging of unexpected inputs/outputs)</li>
</ul>
<h4 id=the-hugging-face-spaces-revolution>The Hugging Face Spaces Revolution<a hidden class=anchor aria-hidden=true href=#the-hugging-face-spaces-revolution>#</a></h4>
<p>Deploying apps developed using either Gradio or Streamlit got a whole lot easier when <a href=https://huggingface.co/>Hugging Face</a> added <a href=https://huggingface.co/spaces>Spaces</a> to their ecosystem of ML products and tools. Spaces are similar to Github Pages &ndash; code is committed to a repository, and the app is automatically build and served. When creating a space, you pick between Streamlit, Gradio, and Static (which more or less replicates Github Pages' static website hosting capabilities). The Space is then automatically setup to accommodate your library of choice. Useful features such as versioning and the ability for users to like a space make it a great experience for the deployment of a public machine learning demo.</p>
<p>Similarly to how Google Colab democratized access to compute resources required for state-of-the-art machine learning models, Hugging Face Spaces allow anyone to host a demo for the world to check out. This means that the entire machine learning workflow, from model training to deployment of an interactive demo, can now be carried out for free and almost entirely in Python.</p>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=https://nicjac.dev/tags/deep-learning/>Deep Learning</a></li>
<li><a href=https://nicjac.dev/tags/ai/>AI</a></li>
<li><a href=https://nicjac.dev/tags/demos/>Demos</a></li>
<li><a href=https://nicjac.dev/tags/gradio/>Gradio</a></li>
<li><a href=https://nicjac.dev/tags/streamlit/>Streamlit</a></li>
<li><a href=https://nicjac.dev/tags/hugging-face/>Hugging Face</a></li>
</ul>
<nav class=paginav>
<a class=next href=https://nicjac.dev/posts/identify-best-model/>
<span class=title>Next Page »</span>
<br>
<span>Good practices for neural network training: identify, save, and document best models</span>
</a>
</nav>
<div class=share-buttons>
<a target=_blank rel="noopener noreferrer" aria-label="share How to Build a Machine Learning Demo in 2022 on twitter" href="https://twitter.com/intent/tweet/?text=How%20to%20Build%20a%20Machine%20Learning%20Demo%20in%c2%a02022&url=https%3a%2f%2fnicjac.dev%2fposts%2fhow-to-build-machine-learning-demo-in-2022%2f&hashtags=DeepLearning%2cAI%2cDemos%2cGradio%2cStreamlit%2cHuggingFace"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share How to Build a Machine Learning Demo in 2022 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fnicjac.dev%2fposts%2fhow-to-build-machine-learning-demo-in-2022%2f&title=How%20to%20Build%20a%20Machine%20Learning%20Demo%20in%c2%a02022&summary=How%20to%20Build%20a%20Machine%20Learning%20Demo%20in%c2%a02022&source=https%3a%2f%2fnicjac.dev%2fposts%2fhow-to-build-machine-learning-demo-in-2022%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share How to Build a Machine Learning Demo in 2022 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fnicjac.dev%2fposts%2fhow-to-build-machine-learning-demo-in-2022%2f&title=How%20to%20Build%20a%20Machine%20Learning%20Demo%20in%c2%a02022"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share How to Build a Machine Learning Demo in 2022 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fnicjac.dev%2fposts%2fhow-to-build-machine-learning-demo-in-2022%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share How to Build a Machine Learning Demo in 2022 on whatsapp" href="https://api.whatsapp.com/send?text=How%20to%20Build%20a%20Machine%20Learning%20Demo%20in%c2%a02022%20-%20https%3a%2f%2fnicjac.dev%2fposts%2fhow-to-build-machine-learning-demo-in-2022%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share How to Build a Machine Learning Demo in 2022 on telegram" href="https://telegram.me/share/url?text=How%20to%20Build%20a%20Machine%20Learning%20Demo%20in%c2%a02022&url=https%3a%2f%2fnicjac.dev%2fposts%2fhow-to-build-machine-learning-demo-in-2022%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg>
</a>
</div>
</footer>
</article>
</main>
<footer class=footer>
<span>&copy; 2022 <a href=https://nicjac.dev/>Reasonable AI</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
<script>document.querySelectorAll('pre > code').forEach(b=>{const c=b.parentNode.parentNode,a=document.createElement('button');a.classList.add('copy-code'),a.innerText='copy';function d(){a.innerText='copied!',setTimeout(()=>{a.innerText='copy'},2e3)}a.addEventListener('click',e=>{if('clipboard'in navigator){navigator.clipboard.writeText(b.textContent),d();return}const a=document.createRange();a.selectNodeContents(b);const c=window.getSelection();c.removeAllRanges(),c.addRange(a);try{document.execCommand('copy'),d()}catch(a){}c.removeRange(a)}),c.classList.contains("highlight")?c.appendChild(a):c.parentNode.firstChild==c||(b.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?b.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(a):b.parentNode.appendChild(a))})</script>
</body>
</html>